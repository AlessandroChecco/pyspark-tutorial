{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyspark syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x102734d30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.context.SQLContext at 0x10795c2b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext #spark data table context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[1] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize(a) #lazy send to spark\n",
    "rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[3] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd =rdd.map(lambda x: x*10) #lazy! it return another rdd\n",
    "rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "450"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.reduce(lambda x,y:x+y) # not lazy (action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[5] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = rdd.filter(lambda x: x>30)\n",
    "rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 50, 60, 70, 80, 90]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "1. Get an RDD with numbers 2 to 10\n",
    "2. Get all elements that are bigger than 5\n",
    "3. Get the product of the elements of the result of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "hide_input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "[6, 7, 8, 9, 10]\n",
      "30240\n"
     ]
    }
   ],
   "source": [
    "rdd =  sc.parallelize(range(2,11))\n",
    "print(rdd.collect())\n",
    "rdd = rdd.filter(lambda x: x >5)\n",
    "print(rdd.collect())\n",
    "rdd = rdd.reduce(lambda x,y: x*y)\n",
    "print(rdd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allcsv = sc.textFile(\"*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Crime ID,Month,Reported by,Falls within,Longitude,Latitude,Location,LSOA code,LSOA name,Crime type,Last outcome category,Context'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allcsv.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Crime ID',\n",
       " 'Month',\n",
       " 'Reported by',\n",
       " 'Falls within',\n",
       " 'Longitude',\n",
       " 'Latitude',\n",
       " 'Location',\n",
       " 'LSOA code',\n",
       " 'LSOA name',\n",
       " 'Crime type',\n",
       " 'Last outcome category',\n",
       " 'Context']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allcsv.map(lambda x: x.split(\",\")).first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuples and ReduceByKey\n",
    "First element of a tuple is considered as key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [['Alexandra','31','F','Python'],['Carla','25','F','C'],['Max','18','M','Scala'],['Tom','34','M','C'],['Philip','28','M','Python'],['Lucy','25','F','Scala'],['Al','18','M','Scala'],['Grace','34','F','Python']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Alexandra', '31', 'F', 'Python'],\n",
       " ['Carla', '25', 'F', 'C'],\n",
       " ['Max', '18', 'M', 'Scala'],\n",
       " ['Tom', '34', 'M', 'C'],\n",
       " ['Philip', '28', 'M', 'Python'],\n",
       " ['Lucy', '25', 'F', 'Scala'],\n",
       " ['Al', '18', 'M', 'Scala'],\n",
       " ['Grace', '34', 'F', 'Python']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RDD = sc.parallelize(data) #send data to spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method reduceByKey in module pyspark.rdd:\n",
      "\n",
      "reduceByKey(func, numPartitions=None, partitionFunc=<function portable_hash at 0x107060a60>) method of pyspark.rdd.RDD instance\n",
      "    Merge the values for each key using an associative and commutative reduce function.\n",
      "    \n",
      "    This will also perform the merging locally on each mapper before\n",
      "    sending results to a reducer, similarly to a \"combiner\" in MapReduce.\n",
      "    \n",
      "    Output will be partitioned with C{numPartitions} partitions, or\n",
      "    the default parallelism level if C{numPartitions} is not specified.\n",
      "    Default partitioner is hash-partition.\n",
      "    \n",
      "    >>> from operator import add\n",
      "    >>> rdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\n",
      "    >>> sorted(rdd.reduceByKey(add).collect())\n",
      "    [('a', 2), ('b', 1)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(RDD.reduceByKey) #exit with q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('F', 4), ('M', 4)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumByGender = RDD.map(lambda t: (t[2],1)).reduceByKey(lambda x,y: x+y)\n",
    "sumByGender.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Python', 31),\n",
       " ('C', 25),\n",
       " ('Scala', 18),\n",
       " ('C', 34),\n",
       " ('Python', 28),\n",
       " ('Scala', 25),\n",
       " ('Scala', 18),\n",
       " ('Python', 34)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languageAndAge = RDD.map(lambda t: (t[3],int(t[1])))\n",
    "languageAndAge.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('C', 59), ('Scala', 61), ('Python', 93)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languageAndAge.reduceByKey(lambda x,y:x+y).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Python', (31, 1)),\n",
       " ('C', (25, 1)),\n",
       " ('Scala', (18, 1)),\n",
       " ('C', (34, 1)),\n",
       " ('Python', (28, 1)),\n",
       " ('Scala', (25, 1)),\n",
       " ('Scala', (18, 1)),\n",
       " ('Python', (34, 1))]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = RDD.map(lambda t: (t[3],(int(t[1]),1)))\n",
    "temp.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('C', (59, 2)), ('Scala', (61, 3)), ('Python', (93, 3))]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp2 = temp.reduceByKey(lambda x,y: (x[0]+y[0],x[1]+y[1]))\n",
    "temp2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('C', 29.5), ('Scala', 20.333333333333332), ('Python', 31.0)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp2.map(lambda x:(x[0],x[1][0]/x[1][1])).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "1. Compute the average age by gender (the key is the first element in the tuple)\n",
    "2. Compute the preferred language by gender (use a tuple as a key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('F', (31, 1)),\n",
       " ('F', (25, 1)),\n",
       " ('M', (18, 1)),\n",
       " ('M', (34, 1)),\n",
       " ('M', (28, 1)),\n",
       " ('F', (25, 1)),\n",
       " ('M', (18, 1)),\n",
       " ('F', (34, 1))]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = RDD.map(lambda t: (t[2],(int(t[1]),1)))\n",
    "temp.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('F', (115, 4)), ('M', (98, 4))]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp2 = temp.reduceByKey(lambda x,y: (x[0]+y[0],x[1]+y[1]))\n",
    "temp2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('F', 28.75), ('M', 24.5)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp2.map(lambda x: (x[0],x[1][0]/x[1][1])).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the preferred language by gender (use a tuple as a key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('F', 'Python'), 1),\n",
       " (('F', 'C'), 1),\n",
       " (('M', 'Scala'), 1),\n",
       " (('M', 'C'), 1),\n",
       " (('M', 'Python'), 1),\n",
       " (('F', 'Scala'), 1),\n",
       " (('M', 'Scala'), 1),\n",
       " (('F', 'Python'), 1)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = RDD.map(lambda t: ((t[2],t[3]),1))\n",
    "temp.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('F', 'Python'), 2),\n",
       " (('M', 'Python'), 1),\n",
       " (('M', 'C'), 1),\n",
       " (('F', 'C'), 1),\n",
       " (('F', 'Scala'), 1),\n",
       " (('M', 'Scala'), 2)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp2 = temp.reduceByKey(lambda x,y: x+y)\n",
    "temp2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('F', ('Python', 2)),\n",
       " ('M', ('Python', 1)),\n",
       " ('M', ('C', 1)),\n",
       " ('F', ('C', 1)),\n",
       " ('F', ('Scala', 1)),\n",
       " ('M', ('Scala', 2))]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp3 = temp2.map(lambda x: (x[0][0],(x[0][1],x[1])))\n",
    "temp3.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('F', ('Scala', 1)), ('M', ('Scala', 2))]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp3.reduceByKey(max).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numer of clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc._jsc.sc().getExecutorMemoryStatus().size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyspark SQL and Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = sqlContext.read.format('com.databricks.spark.csv').options(delimiter=',',header='true', inferschema='true',mode=\"FAILFAST\").load('./crime.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+--------------------+--------------------+---------+---------+--------------------+---------+--------------------+--------------------+---------------------+-------+\n",
      "|            Crime ID|  Month|         Reported by|        Falls within|Longitude| Latitude|            Location|LSOA code|           LSOA name|          Crime type|Last outcome category|Context|\n",
      "+--------------------+-------+--------------------+--------------------+---------+---------+--------------------+---------+--------------------+--------------------+---------------------+-------+\n",
      "|6ce50abd0bf1ca408...|2016-12|Avon and Somerset...|Avon and Somerset...|-2.511571|51.414895|On or near Orchar...|E01014399|Bath and North Ea...|Criminal damage a...|  Under investigation|   null|\n",
      "|6e15f8dd5c88a65c2...|2016-12|Avon and Somerset...|Avon and Somerset...|-2.516919|51.423683|    On or near A4175|E01014399|Bath and North Ea...|Violence and sexu...|  Under investigation|   null|\n",
      "|2594621f67f0a2192...|2016-12|Avon and Somerset...|Avon and Somerset...|-2.511571|51.414895|On or near Orchar...|E01014399|Bath and North Ea...|Violence and sexu...|  Under investigation|   null|\n",
      "|2ba6efa8a8f190fc0...|2016-12|Avon and Somerset...|Avon and Somerset...|-2.495055|51.422132|On or near Cross ...|E01014399|Bath and North Ea...|Violence and sexu...|  Under investigation|   null|\n",
      "|df78d31cd52993672...|2016-12|Avon and Somerset...|Avon and Somerset...|-2.509126|51.416137|On or near St Fra...|E01014399|Bath and North Ea...|         Other crime|  Under investigation|   null|\n",
      "|                null|2016-12|Avon and Somerset...|Avon and Somerset...|-2.498613|51.416002|On or near High S...|E01014400|Bath and North Ea...|Anti-social behav...|                 null|   null|\n",
      "|                null|2016-12|Avon and Somerset...|Avon and Somerset...|-2.497767|51.420232|On or near Chando...|E01014400|Bath and North Ea...|Anti-social behav...|                 null|   null|\n",
      "|                null|2016-12|Avon and Somerset...|Avon and Somerset...| -2.49991|51.413623|On or near Rock Road|E01014400|Bath and North Ea...|Anti-social behav...|                 null|   null|\n",
      "|                null|2016-12|Avon and Somerset...|Avon and Somerset...| -2.49793|51.417966|On or near Statio...|E01014400|Bath and North Ea...|Anti-social behav...|                 null|   null|\n",
      "|9a5c7c81674f4a98c...|2016-12|Avon and Somerset...|Avon and Somerset...|-2.494715|51.419948|On or near Somerd...|E01014400|Bath and North Ea...|       Bicycle theft|  Under investigation|   null|\n",
      "|6d24ca629357cd692...|2016-12|Avon and Somerset...|Avon and Somerset...|-2.498613|51.416002|On or near High S...|E01014400|Bath and North Ea...|Criminal damage a...|  Under investigation|   null|\n",
      "|60cbfd3019af51e03...|2016-12|Avon and Somerset...|Avon and Somerset...|-2.501425|51.416692|On or near Parkin...|E01014400|Bath and North Ea...|         Other theft|  Under investigation|   null|\n",
      "|700bcbbb47736e5c3...|2016-12|Avon and Somerset...|Avon and Somerset...|-2.497767|51.420232|On or near Chando...|E01014400|Bath and North Ea...|         Other theft|  Under investigation|   null|\n",
      "|60cbfd3019af51e03...|2016-12|Avon and Somerset...|Avon and Somerset...|-2.497799|51.415233|On or near Back Lane|E01014400|Bath and North Ea...|         Other theft|  Under investigation|   null|\n",
      "|46cce36dba814c785...|2016-12|Avon and Somerset...|Avon and Somerset...| -2.49854|51.414618|On or near Superm...|E01014400|Bath and North Ea...|         Shoplifting|  Under investigation|   null|\n",
      "|e93f2d271db3d8b7e...|2016-12|Avon and Somerset...|Avon and Somerset...|-2.504289| 51.41828|On or near Tresco...|E01014400|Bath and North Ea...|Violence and sexu...|  Under investigation|   null|\n",
      "|aa43034f57d3111f0...|2016-12|Avon and Somerset...|Avon and Somerset...|-2.501425|51.416692|On or near Parkin...|E01014400|Bath and North Ea...|Violence and sexu...|  Under investigation|   null|\n",
      "|fda8b43830c33fcb5...|2016-12|Avon and Somerset...|Avon and Somerset...|-2.499922|51.417373|On or near Furthe...|E01014400|Bath and North Ea...|Violence and sexu...|  Under investigation|   null|\n",
      "|                null|2016-12|Avon and Somerset...|Avon and Somerset...|-2.506762|51.409116|On or near Queens...|E01014401|Bath and North Ea...|Anti-social behav...|                 null|   null|\n",
      "|                null|2016-12|Avon and Somerset...|Avon and Somerset...|-2.506762|51.409116|On or near Queens...|E01014401|Bath and North Ea...|Anti-social behav...|                 null|   null|\n",
      "+--------------------+-------+--------------------+--------------------+---------+---------+--------------------+---------+--------------------+--------------------+---------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|  Month|          Crime type|\n",
      "+-------+--------------------+\n",
      "|2016-12|Criminal damage a...|\n",
      "|2016-12|Violence and sexu...|\n",
      "|2016-12|Violence and sexu...|\n",
      "|2016-12|Violence and sexu...|\n",
      "|2016-12|         Other crime|\n",
      "|2016-12|Anti-social behav...|\n",
      "|2016-12|Anti-social behav...|\n",
      "|2016-12|Anti-social behav...|\n",
      "|2016-12|Anti-social behav...|\n",
      "|2016-12|       Bicycle theft|\n",
      "|2016-12|Criminal damage a...|\n",
      "|2016-12|         Other theft|\n",
      "|2016-12|         Other theft|\n",
      "|2016-12|         Other theft|\n",
      "|2016-12|         Shoplifting|\n",
      "|2016-12|Violence and sexu...|\n",
      "|2016-12|Violence and sexu...|\n",
      "|2016-12|Violence and sexu...|\n",
      "|2016-12|Anti-social behav...|\n",
      "|2016-12|Anti-social behav...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Month','Crime type').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Crime ID: string (nullable = true)\n",
      " |-- Month: string (nullable = true)\n",
      " |-- Reported by: string (nullable = true)\n",
      " |-- Falls within: string (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- LSOA code: string (nullable = true)\n",
      " |-- LSOA name: string (nullable = true)\n",
      " |-- Crime type: string (nullable = true)\n",
      " |-- Last outcome category: string (nullable = true)\n",
      " |-- Context: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Crime ID: string, Month: string, Reported by: string, Falls within: string, Longitude: double, Latitude: string, Location: string, LSOA code: string, LSOA name: string, Crime type: string, Last outcome category: string, Context: string]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert A as string\n",
    "from pyspark.sql.types import *\n",
    "df.withColumn('Latitude',df['Latitude'].cast(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Crime ID: string (nullable = true)\n",
      " |-- Month: date (nullable = true)\n",
      " |-- Reported by: string (nullable = true)\n",
      " |-- Falls within: string (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- LSOA code: string (nullable = true)\n",
      " |-- LSOA name: string (nullable = true)\n",
      " |-- Crime type: string (nullable = true)\n",
      " |-- Last outcome category: string (nullable = true)\n",
      " |-- Context: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('Month',df['Month'].cast(DateType()))\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|min(Month)|max(Month)|\n",
      "+----------+----------+\n",
      "|2016-12-01|2016-12-01|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean, min, max\n",
    "df.select(min('Month'),max('Month')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see https://databricks.com/blog/2015/06/02/statistical-and-mathematical-functions-with-dataframes-in-spark.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+-------------+--------+-------------------------+-----+-----------+-----------+---------------------+------------+-------+-----------+---------------------+-------------+----------------------------+\n",
      "|LSOA name_Crime Type|Anti-social behaviour|Bicycle theft|Burglary|Criminal damage and arson|Drugs|Other crime|Other theft|Possession of weapons|Public order|Robbery|Shoplifting|Theft from the person|Vehicle crime|Violence and sexual offences|\n",
      "+--------------------+---------------------+-------------+--------+-------------------------+-----+-----------+-----------+---------------------+------------+-------+-----------+---------------------+-------------+----------------------------+\n",
      "|South Gloucesters...|                    1|            0|       0|                        0|    0|          0|          2|                    0|           0|      0|          0|                    0|            0|                           5|\n",
      "|         Mendip 002A|                    2|            0|       0|                        0|    0|          0|          1|                    0|           0|      0|          0|                    0|            0|                           4|\n",
      "|  Taunton Deane 008A|                    0|            0|       0|                        2|    0|          0|          0|                    0|           0|      0|          0|                    0|            0|                           0|\n",
      "|        Bristol 016E|                    2|            0|       2|                        0|    0|          0|          2|                    1|           1|      0|          3|                    0|            0|                           3|\n",
      "|        Bristol 025A|                    6|            1|       2|                        0|    0|          0|          2|                    0|           2|      0|          0|                    0|            1|                           2|\n",
      "|        Bristol 006C|                    0|            0|       1|                        2|    0|          0|          0|                    0|           2|      0|          0|                    0|            2|                           0|\n",
      "|South Gloucesters...|                    1|            0|       0|                        0|    0|          0|          0|                    1|           0|      0|          0|                    0|            0|                           0|\n",
      "| North Somerset 027D|                    2|            0|       1|                        0|    0|          0|          0|                    0|           0|      0|          0|                    0|            2|                           4|\n",
      "|         Mendip 007A|                    2|            1|       2|                        3|    0|          1|          1|                    0|           2|      0|          0|                    0|            0|                           2|\n",
      "| North Somerset 026C|                    3|            0|       0|                        0|    1|          0|          0|                    0|           0|      0|          0|                    0|            0|                           1|\n",
      "| North Somerset 015G|                    5|            0|       1|                        1|    0|          0|          0|                    0|           1|      0|          0|                    0|            0|                           1|\n",
      "|Bath and North Ea...|                    0|            0|       0|                        0|    1|          0|          2|                    0|           0|      0|          0|                    0|            0|                           2|\n",
      "|Bath and North Ea...|                    0|            0|       0|                        0|    0|          0|          0|                    1|           0|      0|          1|                    0|            2|                           0|\n",
      "|South Gloucesters...|                    6|            1|       2|                        2|    0|          0|         23|                    0|           2|      0|         35|                    2|           10|                          11|\n",
      "|         Mendip 011A|                   15|            0|       0|                        1|    0|          0|          3|                    1|           2|      0|          2|                    0|            1|                           8|\n",
      "|        Bristol 054A|                    6|            1|       0|                        3|    0|          0|          0|                    0|           1|      0|          0|                    0|            2|                           3|\n",
      "|        Bristol 042E|                    8|            0|       0|                        2|    0|          0|          1|                    0|           0|      0|          0|                    0|            1|                           2|\n",
      "|  Taunton Deane 007D|                    6|            0|       0|                        2|    0|          1|          1|                    0|           4|      0|          1|                    0|            0|                           3|\n",
      "|South Gloucesters...|                    1|            0|       0|                        0|    0|          0|          0|                    0|           1|      0|          0|                    0|            0|                           0|\n",
      "|  West Somerset 001F|                    0|            0|       0|                        0|    0|          0|          0|                    0|           1|      0|          0|                    0|            1|                           1|\n",
      "+--------------------+---------------------+-------------+--------+-------------------------+-----+-----------+-----------+---------------------+------------+-------+-----------+---------------------+-------------+----------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.stat.crosstab(\"LSOA name\", \"Crime Type\").show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can go to http://bigdata1.sheffield.ac.uk:50070/explorer.html#/data/ukpolice to see the hfs filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+\n",
      "|Crime type| Latitude|Longitude|\n",
      "+----------+---------+---------+\n",
      "|  Burglary| 51.41364|-2.498127|\n",
      "|  Burglary|51.395315|-2.391594|\n",
      "|  Burglary|51.392676|-2.350423|\n",
      "|  Burglary|51.388973|-2.352608|\n",
      "|  Burglary|51.391003|-2.356346|\n",
      "|  Burglary|51.391003|-2.356346|\n",
      "|  Burglary|51.386211|-2.359211|\n",
      "|  Burglary|51.380421|-2.358907|\n",
      "|  Burglary|51.386211|-2.359211|\n",
      "|  Burglary|51.389609|-2.390367|\n",
      "|  Burglary|51.383968| -2.36339|\n",
      "|  Burglary|51.381522|-2.363543|\n",
      "|  Burglary| 51.38013|-2.365745|\n",
      "|  Burglary|51.383162|-2.368039|\n",
      "|  Burglary|51.383414|-2.370958|\n",
      "|  Burglary|51.390704|-2.319911|\n",
      "|  Burglary|51.328447|-2.371088|\n",
      "|  Burglary|51.323676|-2.369973|\n",
      "|  Burglary| 51.37917|-2.392864|\n",
      "|  Burglary|51.374852|-2.382799|\n",
      "+----------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df[\"Crime type\"] == 'Burglary').select(df['Crime type'],df.Latitude,df.Longitude).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*Project [Crime type#9, Latitude#5, Longitude#4]\n",
      "+- *Filter (isnotnull(Crime type#9) && (Crime type#9 = Burglary))\n",
      "   +- *FileScan csv [Longitude#4,Latitude#5,Crime type#9] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/alessandro/Desktop/pyspark-tutorial-solved-master 2/crime.csv], PartitionFilters: [], PushedFilters: [IsNotNull(Crime type), EqualTo(Crime type,Burglary)], ReadSchema: struct<Longitude:double,Latitude:double,Crime type:string>\n"
     ]
    }
   ],
   "source": [
    "df.filter(df[\"Crime type\"] == 'Burglary').select(df['Crime type'],df.Latitude,df.Longitude).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+\n",
      "|Latitude|Longitude|\n",
      "+--------+---------+\n",
      "|Burglary|-2.498127|\n",
      "|Burglary|-2.391594|\n",
      "|Burglary|-2.350423|\n",
      "|Burglary|-2.352608|\n",
      "|Burglary|-2.356346|\n",
      "|Burglary|-2.356346|\n",
      "|Burglary|-2.359211|\n",
      "|Burglary|-2.358907|\n",
      "|Burglary|-2.359211|\n",
      "|Burglary|-2.390367|\n",
      "|Burglary| -2.36339|\n",
      "|Burglary|-2.363543|\n",
      "|Burglary|-2.365745|\n",
      "|Burglary|-2.368039|\n",
      "|Burglary|-2.370958|\n",
      "|Burglary|-2.319911|\n",
      "|Burglary|-2.371088|\n",
      "|Burglary|-2.369973|\n",
      "|Burglary|-2.392864|\n",
      "|Burglary|-2.382799|\n",
      "+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#or equivalently\n",
    "sqlContext.registerDataFrameAsTable(df, \"table1\")\n",
    "sqlContext.sql('select `Crime type` Latitude, Longitude from table1 where `Crime type` == \"Burglary\"').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*Project [Crime type#9 AS Latitude#265, Longitude#4]\n",
      "+- *Filter (isnotnull(Crime type#9) && (Crime type#9 = Burglary))\n",
      "   +- *FileScan csv [Longitude#4,Crime type#9] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/alessandro/Desktop/pyspark-tutorial-solved-master 2/crime.csv], PartitionFilters: [], PushedFilters: [IsNotNull(Crime type), EqualTo(Crime type,Burglary)], ReadSchema: struct<Longitude:double,Crime type:string>\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('select `Crime type` Latitude, Longitude from table1 where `Crime type` == \"Burglary\"').explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13750"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cache() # put the df in cache and results will be cached too (try to run a count twice after this)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13750"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------------------+\n",
      "|Longitude| Latitude|Longitude_times_two|\n",
      "+---------+---------+-------------------+\n",
      "|-2.511571|51.414895|          -5.023142|\n",
      "|-2.516919|51.423683|          -5.033838|\n",
      "|-2.511571|51.414895|          -5.023142|\n",
      "|-2.495055|51.422132|           -4.99011|\n",
      "|-2.509126|51.416137|          -5.018252|\n",
      "|-2.498613|51.416002|          -4.997226|\n",
      "|-2.497767|51.420232|          -4.995534|\n",
      "| -2.49991|51.413623|           -4.99982|\n",
      "| -2.49793|51.417966|           -4.99586|\n",
      "|-2.494715|51.419948|           -4.98943|\n",
      "|-2.498613|51.416002|          -4.997226|\n",
      "|-2.501425|51.416692|           -5.00285|\n",
      "|-2.497767|51.420232|          -4.995534|\n",
      "|-2.497799|51.415233|          -4.995598|\n",
      "| -2.49854|51.414618|           -4.99708|\n",
      "|-2.504289| 51.41828|          -5.008578|\n",
      "|-2.501425|51.416692|           -5.00285|\n",
      "|-2.499922|51.417373|          -4.999844|\n",
      "|-2.506762|51.409116|          -5.013524|\n",
      "|-2.506762|51.409116|          -5.013524|\n",
      "+---------+---------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# adding columns and keeping existing ones F.lit(0) return a column\n",
    "from pyspark.sql import functions as F\n",
    "df.withColumn('zero', F.lit(0))\n",
    "df.select('Longitude','Latitude').withColumn('Longitude_times_two', df.Longitude * 2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------------+\n",
      "| Latitude|  new_Lat|negative_long|\n",
      "+---------+---------+-------------+\n",
      "|51.414895|51.414895|         true|\n",
      "|51.423683|51.423683|         true|\n",
      "|51.414895|51.414895|         true|\n",
      "|51.422132|51.422132|         true|\n",
      "|51.416137|51.416137|         true|\n",
      "|51.416002|51.416002|         true|\n",
      "|51.420232|51.420232|         true|\n",
      "|51.413623|51.413623|         true|\n",
      "|51.417966|51.417966|         true|\n",
      "|51.419948|51.419948|         true|\n",
      "|51.416002|51.416002|         true|\n",
      "|51.416692|51.416692|         true|\n",
      "|51.420232|51.420232|         true|\n",
      "|51.415233|51.415233|         true|\n",
      "|51.414618|51.414618|         true|\n",
      "| 51.41828| 51.41828|         true|\n",
      "|51.416692|51.416692|         true|\n",
      "|51.417373|51.417373|         true|\n",
      "|51.409116|51.409116|         true|\n",
      "|51.409116|51.409116|         true|\n",
      "+---------+---------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, first, last, sum, count, countDistinct, desc #*\n",
    "# selecting columns, and creating new ones\n",
    "df.select('Latitude', col('Latitude').alias('new_Lat'), (col('Longitude') < 0 ).alias('negative_long')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Crime ID: string (nullable = true)\n",
      " |-- Month: date (nullable = true)\n",
      " |-- Reported by: string (nullable = true)\n",
      " |-- Falls within: string (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- LSOA code: string (nullable = true)\n",
      " |-- LSOA name: string (nullable = true)\n",
      " |-- Crime type: string (nullable = true)\n",
      " |-- Last outcome category: string (nullable = true)\n",
      " |-- Context: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|          Crime type|              status|\n",
      "+--------------------+--------------------+\n",
      "|       Bicycle theft| Under investigation|\n",
      "|        Public order| Under investigation|\n",
      "|               Drugs|Awaiting court ou...|\n",
      "|         Other crime| Under investigation|\n",
      "|             Robbery| Under investigation|\n",
      "|Criminal damage a...| Under investigation|\n",
      "|Theft from the pe...| Under investigation|\n",
      "|         Shoplifting| Under investigation|\n",
      "|            Burglary| Under investigation|\n",
      "|         Other theft| Under investigation|\n",
      "|Possession of wea...|Awaiting court ou...|\n",
      "|Violence and sexu...| Under investigation|\n",
      "|       Vehicle crime| Under investigation|\n",
      "|Anti-social behav...|                null|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Crime type').agg(first('Last outcome category').alias(\"status\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "1. Show how many crimes we have for each crime type (hint: use groupby, agg and count)\n",
    "2. Show how many *distinct*  'Last outcome category' we have for each Crime type\n",
    "3. Show how many crimes we have for each LSOA code and crime type (hint: groupy by two keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "1. show the LSOA names where the number of crimes is bigger than 100 (use groupby count and where)\n",
    "2. sort them by count of crimes\n",
    "3. see help(df.stat.freqItems) and show the crimes and lsoa name appearing  more than 30% (hint support is 0.3, use show(truncate=False) to see the result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = sqlContext.read.json('/data/INF6032Coursework/statuses.log.2014-12-30.gz') # you can use wildcards to load multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.limit(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = df2.select([\"user\",\"entities\", \"lang\", \"retweeted\", \"favorited\",\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user: struct (nullable = true)\n",
      " |    |-- contributors_enabled: boolean (nullable = true)\n",
      " |    |-- created_at: string (nullable = true)\n",
      " |    |-- default_profile: boolean (nullable = true)\n",
      " |    |-- default_profile_image: boolean (nullable = true)\n",
      " |    |-- description: string (nullable = true)\n",
      " |    |-- favourites_count: long (nullable = true)\n",
      " |    |-- follow_request_sent: string (nullable = true)\n",
      " |    |-- followers_count: long (nullable = true)\n",
      " |    |-- following: string (nullable = true)\n",
      " |    |-- friends_count: long (nullable = true)\n",
      " |    |-- geo_enabled: boolean (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- id_str: string (nullable = true)\n",
      " |    |-- is_translator: boolean (nullable = true)\n",
      " |    |-- lang: string (nullable = true)\n",
      " |    |-- listed_count: long (nullable = true)\n",
      " |    |-- location: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- notifications: string (nullable = true)\n",
      " |    |-- profile_background_color: string (nullable = true)\n",
      " |    |-- profile_background_image_url: string (nullable = true)\n",
      " |    |-- profile_background_image_url_https: string (nullable = true)\n",
      " |    |-- profile_background_tile: boolean (nullable = true)\n",
      " |    |-- profile_banner_url: string (nullable = true)\n",
      " |    |-- profile_image_url: string (nullable = true)\n",
      " |    |-- profile_image_url_https: string (nullable = true)\n",
      " |    |-- profile_link_color: string (nullable = true)\n",
      " |    |-- profile_sidebar_border_color: string (nullable = true)\n",
      " |    |-- profile_sidebar_fill_color: string (nullable = true)\n",
      " |    |-- profile_text_color: string (nullable = true)\n",
      " |    |-- profile_use_background_image: boolean (nullable = true)\n",
      " |    |-- protected: boolean (nullable = true)\n",
      " |    |-- screen_name: string (nullable = true)\n",
      " |    |-- statuses_count: long (nullable = true)\n",
      " |    |-- time_zone: string (nullable = true)\n",
      " |    |-- url: string (nullable = true)\n",
      " |    |-- utc_offset: long (nullable = true)\n",
      " |    |-- verified: boolean (nullable = true)\n",
      " |-- entities: struct (nullable = true)\n",
      " |    |-- hashtags: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- text: string (nullable = true)\n",
      " |    |-- media: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- media_url: string (nullable = true)\n",
      " |    |    |    |-- media_url_https: string (nullable = true)\n",
      " |    |    |    |-- sizes: struct (nullable = true)\n",
      " |    |    |    |    |-- large: struct (nullable = true)\n",
      " |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |-- medium: struct (nullable = true)\n",
      " |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |-- small: struct (nullable = true)\n",
      " |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |-- thumb: struct (nullable = true)\n",
      " |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |-- source_status_id: long (nullable = true)\n",
      " |    |    |    |-- source_status_id_str: string (nullable = true)\n",
      " |    |    |    |-- type: string (nullable = true)\n",
      " |    |    |    |-- url: string (nullable = true)\n",
      " |    |-- symbols: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- text: string (nullable = true)\n",
      " |    |-- trends: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- urls: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- url: string (nullable = true)\n",
      " |    |-- user_mentions: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |-- screen_name: string (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- retweeted: boolean (nullable = true)\n",
      " |-- favorited: boolean (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|        id|                text|\n",
      "+----------+--------------------+\n",
      "| 320075522|2.5C 85%RH\n",
      "WChill...|\n",
      "|1464742728|RT @johnny_cidade...|\n",
      "|1729753068|RT @basakburcuyuz...|\n",
      "| 384026199|@willylevy29 te e...|\n",
      "| 211369327|@elNinoRodriguez ...|\n",
      "| 134842190|RT @XimePonceLeon...|\n",
      "|  16409225|RT @ComplexMag: R...|\n",
      "| 510414395|@maumachado7 cheg...|\n",
      "| 709905230|watching $XOXO ha...|\n",
      "| 231423897|@ddlovato I LOVE ...|\n",
      "|2891486949|\"Osmanlnn eski ...|\n",
      "| 394122530|RT @AtillaTasNet:...|\n",
      "| 111785560|               Voooa|\n",
      "|2613730124|@Leeds_Demon @Rev...|\n",
      "| 349172091|http://t.co/xkAbL...|\n",
      "| 275424344|{   ...|\n",
      "|2892644994|   ...|\n",
      "|  45019996|Apple to keep cen...|\n",
      "|2873037495|RT @bi3f2:  ...|\n",
      "|2283309781|RT @Laudya_Cynth1...|\n",
      "+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# view the contents of a column\n",
    "print(df2.select(['user.id','text']).show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|lang|count|\n",
      "+----+-----+\n",
      "|null| 2750|\n",
      "|  en|  864|\n",
      "|  ja|  332|\n",
      "|  es|  254|\n",
      "|  ar|  201|\n",
      "|  pt|  137|\n",
      "| und|  108|\n",
      "|  ru|   78|\n",
      "|  fr|   62|\n",
      "|  in|   61|\n",
      "|  tr|   40|\n",
      "|  it|   28|\n",
      "|  ko|   14|\n",
      "|  nl|   10|\n",
      "|  et|   10|\n",
      "|  de|    9|\n",
      "|  tl|    6|\n",
      "|  pl|    6|\n",
      "|  zh|    3|\n",
      "|  bg|    3|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# list the most common languages\n",
    "print(df.groupby('lang').count().sort(desc('count')).show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get a dataframe of the user data\n",
    "user_df = df2.select('user.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+---------------+\n",
      "|        id|          created_at|            location|    screen_name|\n",
      "+----------+--------------------+--------------------+---------------+\n",
      "| 320075522|Sun Jun 19 07:49:...|South Lakes, Cumbria| CumbriaWeather|\n",
      "|1464742728|Tue May 28 14:02:...|          margem sul| barbarafchanel|\n",
      "|1729753068|Wed Sep 04 20:11:...|                    |        biyokin|\n",
      "| 384026199|Sun Oct 02 23:10:...|          Araraquara|      patyleyte|\n",
      "| 211369327|Wed Nov 03 01:58:...|        Buenos Aires|    condobleene|\n",
      "| 134842190|Mon Apr 19 16:10:...|                    |GinaGodoyAndrad|\n",
      "|  16409225|Mon Sep 22 20:19:...|           Same City|       aehorton|\n",
      "| 510414395|Thu Mar 01 15:37:...|      Uruguay/Rivera|       jorge_o7|\n",
      "| 709905230|Sun Jul 22 01:56:...|    Neckar York City|  NeckarPlunger|\n",
      "| 231423897|Tue Dec 28 13:43:...|                    |   lovaticadeIa|\n",
      "|2891486949|Tue Nov 25 01:01:...|                bak|     TalanFahri|\n",
      "| 394122530|Wed Oct 19 16:12:...|                    |     filizpalaz|\n",
      "| 111785560|Sat Feb 06 03:57:...|                    |  4allthelovers|\n",
      "|2613730124|Wed Jul 09 15:20:...|The north of England|    WKGrainger1|\n",
      "| 349172091|Fri Aug 05 17:37:...|            Trappin |    westtrade23|\n",
      "| 275424344|Fri Apr 01 07:29:...|              |        3bodksa|\n",
      "|2892644994|Fri Nov 07 10:40:...|                    |        sal_776|\n",
      "|  45019996|Fri Jun 05 22:51:...| Calgary, Alberta CA|         mltstr|\n",
      "|2873037495|Tue Nov 11 23:06:...|                    |  Vtoejrohezaxo|\n",
      "|2283309781|Thu Jan 09 09:00:...|      Padang-Bandung|     Rafiqaznur|\n",
      "+----------+--------------------+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df.select([\"id\",\"created_at\",\"location\",\"screen_name\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count of tweets per user\n",
    "tweets = user_df.groupby('screen_name').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|    screen_name|count|\n",
      "+---------------+-----+\n",
      "|     VxTwitPr05|    4|\n",
      "|      lawleywow|    3|\n",
      "|      KisTamaRT|    2|\n",
      "|      abboafeef|    2|\n",
      "|         AntNom|    2|\n",
      "|        imxeex_|    2|\n",
      "|    funnyfranta|    2|\n",
      "|    clemensfalk|    2|\n",
      "|     Unbrokkken|    2|\n",
      "| akuinisiapalah|    2|\n",
      "|dameLyudmilabot|    2|\n",
      "|DeadpoolTheBest|    2|\n",
      "|        drodhen|    2|\n",
      "|    seashell_98|    2|\n",
      "|   Domipictures|    2|\n",
      "| CumbriaWeather|    1|\n",
      "| barbarafchanel|    1|\n",
      "|        biyokin|    1|\n",
      "|    condobleene|    1|\n",
      "|      patyleyte|    1|\n",
      "+---------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show how many times the most active users have tweeted\n",
    "tweets.sort(desc('count')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|       avg(count)|\n",
      "+-----------------+\n",
      "|2.239140170174653|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show the mean number of tweets per person\n",
    "tweeters.select(mean('count')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+-----------------+------------------+----+\n",
      "|summary|  favourites_count|  followers_count|    friends_count|    statuses_count|lang|\n",
      "+-------+------------------+-----------------+-----------------+------------------+----+\n",
      "|  count|              2250|             2250|             2250|              2250|2250|\n",
      "|   mean|3638.6657777777777|4495.716444444444|1364.255111111111|24759.810222222222|null|\n",
      "| stddev| 15508.34313676943|35566.39674557091|5158.005672569562| 62757.04774486603|null|\n",
      "|    min|                 0|                0|                0|                 1|  ar|\n",
      "|    max|            391348|           901263|            84651|           1132818|  zh|\n",
      "+-------+------------------+-----------------+-----------------+------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get a dataframe of the users and the retweeted / favorited status\n",
    "# This allows us to select values that are contained in nested dataframes\n",
    "refined_df = df.select(['user.favourites_count', 'user.followers_count',\n",
    "                        'user.friends_count', 'user.statuses_count', 'lang',\n",
    "                        'retweeted', 'favorited'])\n",
    "refined_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----+---------+---------+--------------------+\n",
      "|                user|            entities|lang|retweeted|favorited|                text|\n",
      "+--------------------+--------------------+----+---------+---------+--------------------+\n",
      "|[false,Tue Dec 09...|[WrappedArray([Wr...| und|    false|    false|@VxTwitPr06 Hi @V...|\n",
      "|[false,Tue Dec 09...|[WrappedArray([Wr...| und|    false|    false|@VxTwitPr06 Hi @V...|\n",
      "|[false,Tue Dec 09...|[WrappedArray([Wr...| und|    false|    false|@VxTwitPr06 Hi @V...|\n",
      "|[false,Fri Jan 31...|[WrappedArray([Wr...|  in|    false|    false|Berharap tetap di...|\n",
      "|[false,Tue Dec 09...|[WrappedArray([Wr...| und|    false|    false|@VxTwitPr06 Hi @V...|\n",
      "|[false,Wed May 22...|[WrappedArray(),n...|  en|    false|    false|RT @bendragonborn...|\n",
      "|[false,Mon Dec 22...|[WrappedArray([Wr...|  en|    false|    false|@KenyanExport Can...|\n",
      "|[false,Tue Dec 09...|[WrappedArray(),n...|  en|    false|    false|RT @BobBurg: The ...|\n",
      "|[false,Mon Jan 18...|[WrappedArray(),n...|  pt|    false|    false|Um homem de equil...|\n",
      "|[false,Tue Jun 02...|[WrappedArray(),n...|  en|    false|    false|Hearing Ender say...|\n",
      "|[false,Mon May 10...|[WrappedArray(),n...|  en|    false|    false|@FredBrooklyn - l...|\n",
      "|[false,Mon Nov 18...|[WrappedArray(),n...|  es|    false|    false|Cul es tu traba...|\n",
      "|[false,Tue Nov 29...|[WrappedArray([Wr...|  en|    false|    false|RT @itsHIMYMquote...|\n",
      "+--------------------+--------------------+----+---------+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#match hashtag or specific text\n",
    "df2.filter(col('text').rlike(\"(?i)(test|#hi).*\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see http://www.regex101.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "1. Create a dataframe (from df) containing only the user information (nested) and the columns \"retweeted\" and \"text\"\n",
    "2. remove the rows that are null in the column \"text\"\n",
    "3. filter only the rows that has \"retweeted\" == False\n",
    "4. show the text of the previous step\n",
    "5. show the text from previous step that contains the word johnny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File creation and batch submission\n",
    "- create a text file with the following text:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "\"\"\"Example code for running pyspark on the twitter data set.\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext, DataFrame\n",
    "from pyspark.sql.functions import desc, mean\n",
    "\n",
    "sc = SparkContext()\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "df = sqlContext.read.json('/data/INF6032Coursework/statuses.log.2014-12-30.gz')\n",
    "\n",
    "# clean df and select the columns are are interested in\n",
    "df = df.na.drop(subset=[\"user.id\"]).select([\"user\",\"entities\", \"lang\", \"retweeted\", \"favorited\"])\n",
    "\n",
    "# take only the first 5000 rows\n",
    "df = df.limit(5000)\n",
    "\n",
    "print(df.show())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- add your code to the end\n",
    "- name it with .py extension\n",
    "- upload it to http://bigdata1.sheffield.ac.uk:8888/filebrowser/\n",
    "- from the console, exit pyspark with exit() and download the file with\n",
    "```\n",
    "hdfs dfs -get /user/username/script.py\n",
    "```\n",
    "- run your script with  spark-submit script.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
